{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc5a7d74",
   "metadata": {},
   "source": [
    "# Identifying Entities in Healthcare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaa5941",
   "metadata": {},
   "source": [
    " Workspace set up: Import and Install useful packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db0fbae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycrf in c:\\users\\sukht\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: sklearn-crfsuite in c:\\users\\sukht\\anaconda3\\lib\\site-packages (0.3.6)\n",
      "Requirement already satisfied: python-crfsuite>=0.8.3 in c:\\users\\sukht\\anaconda3\\lib\\site-packages (from sklearn-crfsuite) (0.9.10)\n",
      "Requirement already satisfied: six in c:\\users\\sukht\\anaconda3\\lib\\site-packages (from sklearn-crfsuite) (1.16.0)\n",
      "Requirement already satisfied: tabulate in c:\\users\\sukht\\anaconda3\\lib\\site-packages (from sklearn-crfsuite) (0.8.10)\n",
      "Requirement already satisfied: tqdm>=2.0 in c:\\users\\sukht\\anaconda3\\lib\\site-packages (from sklearn-crfsuite) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sukht\\anaconda3\\lib\\site-packages (from tqdm>=2.0->sklearn-crfsuite) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install pycrf\n",
    "!pip install sklearn-crfsuite\n",
    "\n",
    "import spacy\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "model = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0fcefd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a05ca4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to process the file and return a sentence list\n",
    "def preprocess_inputfile(input_file):\n",
    "    i_file = open(input_file, 'r')\n",
    "    file_name = i_file.readlines()\n",
    "    i_file.close()\n",
    "\n",
    "    output_list = []\n",
    "\n",
    "    full_sentence = \"\"\n",
    "\n",
    "    for each_word in file_name:\n",
    "        each_word = each_word.strip()\n",
    "        if each_word == \"\":\n",
    "            output_list.append(full_sentence) # To append the complete sentence to the output list\n",
    "            full_sentence = \"\" # For new sentence start\n",
    "        else:\n",
    "            if full_sentence:\n",
    "                full_sentence += \" \" + each_word\n",
    "            else:\n",
    "                full_sentence = each_word\n",
    "\n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44694395",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sukht\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6fd2d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sent = preprocess_inputfile('train_sent')\n",
    "train_label = preprocess_inputfile('train_label')\n",
    "test_sent = preprocess_inputfile('test_sent')\n",
    "test_label = preprocess_inputfile('test_label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c582c0c",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce47806",
   "metadata": {},
   "source": [
    "The dataset provided is in the form of one word per line. Let's understand the format of data below:\n",
    "\n",
    "Suppose there are x words in a sentence, then there will be x continuous lines with one word in each line.\n",
    "\n",
    "Further, the two sentences are separated by empty lines. The labels for the data follow the same format. We need to pre-process the data to recover the complete sentences and their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbc77c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1 is: All live births > or = 23 weeks at the University of Vermont in 1995 ( n = 2395 ) were retrospectively analyzed for delivery route , indication for cesarean , gestational age , parity , and practice group ( to reflect risk status )\n",
      "Label 1 is: O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "****************************************************************************************************\n",
      "Sentence 2 is: The total cesarean rate was 14.4 % ( 344 of 2395 ) , and the primary rate was 11.4 % ( 244 of 2144 )\n",
      "Label 2 is: O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "****************************************************************************************************\n",
      "Sentence 3 is: Abnormal presentation was the most common indication ( 25.6 % , 88 of 344 )\n",
      "Label 3 is: O O O O O O O O O O O O O O O\n",
      "****************************************************************************************************\n",
      "Sentence 4 is: The `` corrected '' cesarean rate ( maternal-fetal medicine and transported patients excluded ) was 12.4 % ( 273 of 2194 ) , and the `` corrected '' primary rate was 9.6 % ( 190 of 1975 )\n",
      "Label 4 is: O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "****************************************************************************************************\n",
      "Sentence 5 is: Arrest of dilation was the most common indication in both `` corrected '' subgroups ( 23.4 and 24.6 % , respectively )\n",
      "Label 5 is: O O O O O O O O O O O O O O O O O O O O O O\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Print first five sentences from the processed dataset\n",
    "for each_item in range(5):\n",
    "    print(f\"Sentence {each_item+1} is: {train_sent[each_item]}\")\n",
    "    print(f\"Label {each_item+1} is: {train_label[each_item]}\")\n",
    "    print(\"*\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52f7ba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the train and test sentences and labels\n",
    "with open('train_sent', 'r') as train_sent_file:\n",
    "  train_words = train_sent_file.readlines()\n",
    "\n",
    "with open('train_label', 'r') as train_labels_file:\n",
    "  train_labels_by_word = train_labels_file.readlines()\n",
    "\n",
    "with open('test_sent', 'r') as test_sent_file:\n",
    "  test_words = test_sent_file.readlines()\n",
    "\n",
    "with open('test_label', 'r') as test_labels_file:\n",
    "  test_labels_by_word = test_labels_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "680161c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of tokens in training set\n",
      " No. of words:  48501 \n",
      "No. of labels:  48501\n",
      "\n",
      "\n",
      "Count of tokens in test set\n",
      " No. of words:  19674 \n",
      "No. of labels:  19674\n"
     ]
    }
   ],
   "source": [
    "# Sanity check to see that the number of tokens and no. of corresponding labels match.\n",
    "print(\"Count of tokens in training set\\n\",\"No. of words: \",len(train_words),\"\\nNo. of labels: \",len(train_labels_by_word))\n",
    "print(\"\\n\\nCount of tokens in test set\\n\",\"No. of words: \",len(test_words),\"\\nNo. of labels: \",len(test_labels_by_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5594f040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDFfromFile(file_name, df_col_name):\n",
    "\n",
    "  import re\n",
    "  file = open(file_name, \"r\")\n",
    "  wordlist = []\n",
    "  sent = []\n",
    "  for word in file:\n",
    "    if word == '\\n':\n",
    "      # sentence complete store previous sent\n",
    "      full_sent = ' '.join(wordlist)\n",
    "      sent.append(full_sent)\n",
    "      full_sent=''\n",
    "      wordlist = []\n",
    "    else:\n",
    "      w = word.replace('\\n','')\n",
    "      wordlist.append(w)\n",
    "\n",
    "  df = pd.DataFrame({df_col_name:sent})\n",
    "  return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b5b5f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Sentence #  index\n",
      "0     All live births > or = 23 weeks at the Univers...      0\n",
      "1     The total cesarean rate was 14.4 % ( 344 of 23...      1\n",
      "2     Abnormal presentation was the most common indi...      2\n",
      "3     The `` corrected '' cesarean rate ( maternal-f...      3\n",
      "4     Arrest of dilation was the most common indicat...      4\n",
      "...                                                 ...    ...\n",
      "2594  Special report : comparative efficacy of diffe...   2594\n",
      "2595  Special report : pressure-reducing support sur...   2595\n",
      "2596  External counterpulsation for treatment of chr...   2596\n",
      "2597  Intra-articular hyaluronan injections for trea...   2597\n",
      "2598               Pneumococcal vaccine : a second look   2598\n",
      "\n",
      "[2599 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Create Train_sentences df\n",
    "df_train_sent = createDFfromFile( 'train_sent', df_col_name='Sentence #')\n",
    "df_train_sent['index'] = df_train_sent.index\n",
    "print(df_train_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98a03459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Sentence #  index\n",
      "0     O O O O O O O O O O O O O O O O O O O O O O O ...      0\n",
      "1     O O O O O O O O O O O O O O O O O O O O O O O O O      1\n",
      "2                         O O O O O O O O O O O O O O O      2\n",
      "3     O O O O O O O O O O O O O O O O O O O O O O O ...      3\n",
      "4           O O O O O O O O O O O O O O O O O O O O O O      4\n",
      "...                                                 ...    ...\n",
      "2594                  O O O O O O O O O T T T O O O O D   2594\n",
      "2595                O O O T T T O O O O O O D D O O O O   2595\n",
      "2596                                  T T O O O D D D D   2596\n",
      "2597                                T T T O O O D O O O   2597\n",
      "2598                                        D T O O O O   2598\n",
      "\n",
      "[2599 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Similarly create for train_label, test_sent, test_label df\n",
    "df_train_label = createDFfromFile( 'train_label', df_col_name='Sentence #')\n",
    "df_train_label['index'] = df_train_label.index\n",
    "print(df_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bf0ac80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Sentence #  index\n",
      "0     Furthermore , when all deliveries were analyze...      0\n",
      "1     As the ambient temperature increases , there i...      1\n",
      "2     The daily high temperature ranged from 71 to 1...      2\n",
      "3     There was a significant correlation between th...      3\n",
      "4     Fluctuations in ambient temperature are invers...      4\n",
      "...                                                 ...    ...\n",
      "1051  Reduction of vasoreactivity and thrombogenicit...   1051\n",
      "1052  Effects of ultrasound energy on total peripher...   1052\n",
      "1053  High-dose chemotherapy with autologous stem-ce...   1053\n",
      "1054  `` Tandem '' high-dose chemoradiotherapy with ...   1054\n",
      "1055  Intravenous immune globulin for recurrent spon...   1055\n",
      "\n",
      "[1056 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_test_sent = createDFfromFile( 'test_sent', df_col_name='Sentence #')\n",
    "df_test_sent['index'] = df_test_sent.index\n",
    "print(df_test_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60767228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Sentence #  index\n",
      "0     O O O O O O O O O O O O O O O O O O O O O O O ...      0\n",
      "1                 O O O O O O O O O O O O O O O O O O O      1\n",
      "2       O O O O O O O O O O O O O O O O O O O O O O O O      2\n",
      "3     O O O O O O O O O O O O O O O O O O O O O O O ...      3\n",
      "4                                 O O O O O O O O O O O      4\n",
      "...                                                 ...    ...\n",
      "1051                          O O D O D O T T O O O T T   1051\n",
      "1052                    O O T T O D D D D O O O O O O O   1052\n",
      "1053                                T T T T T T O D D D   1053\n",
      "1054              T T T T T T T T T O O O O O O O O D D   1054\n",
      "1055                                      T T T O D D D   1055\n",
      "\n",
      "[1056 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_test_label = createDFfromFile( 'test_label', df_col_name='Sentence #')\n",
    "df_test_label['index'] = df_test_label.index\n",
    "print(df_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2446a7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Sentence #_x  index  \\\n",
      "0     All live births > or = 23 weeks at the Univers...      0   \n",
      "1     The total cesarean rate was 14.4 % ( 344 of 23...      1   \n",
      "2     Abnormal presentation was the most common indi...      2   \n",
      "3     The `` corrected '' cesarean rate ( maternal-f...      3   \n",
      "4     Arrest of dilation was the most common indicat...      4   \n",
      "...                                                 ...    ...   \n",
      "2594  Special report : comparative efficacy of diffe...   2594   \n",
      "2595  Special report : pressure-reducing support sur...   2595   \n",
      "2596  External counterpulsation for treatment of chr...   2596   \n",
      "2597  Intra-articular hyaluronan injections for trea...   2597   \n",
      "2598               Pneumococcal vaccine : a second look   2598   \n",
      "\n",
      "                                           Sentence #_y  \n",
      "0     O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
      "1     O O O O O O O O O O O O O O O O O O O O O O O O O  \n",
      "2                         O O O O O O O O O O O O O O O  \n",
      "3     O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
      "4           O O O O O O O O O O O O O O O O O O O O O O  \n",
      "...                                                 ...  \n",
      "2594                  O O O O O O O O O T T T O O O O D  \n",
      "2595                O O O T T T O O O O O O D D O O O O  \n",
      "2596                                  T T O O O D D D D  \n",
      "2597                                T T T O O O D O O O  \n",
      "2598                                        D T O O O O  \n",
      "\n",
      "[2599 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge the two to form one dataset of all train data\n",
    "df_train_data = pd.merge(df_train_sent, df_train_label, on=\"index\")\n",
    "print(df_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b07395c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Sentence #_x  index  \\\n",
      "0     Furthermore , when all deliveries were analyze...      0   \n",
      "1     As the ambient temperature increases , there i...      1   \n",
      "2     The daily high temperature ranged from 71 to 1...      2   \n",
      "3     There was a significant correlation between th...      3   \n",
      "4     Fluctuations in ambient temperature are invers...      4   \n",
      "...                                                 ...    ...   \n",
      "1051  Reduction of vasoreactivity and thrombogenicit...   1051   \n",
      "1052  Effects of ultrasound energy on total peripher...   1052   \n",
      "1053  High-dose chemotherapy with autologous stem-ce...   1053   \n",
      "1054  `` Tandem '' high-dose chemoradiotherapy with ...   1054   \n",
      "1055  Intravenous immune globulin for recurrent spon...   1055   \n",
      "\n",
      "                                           Sentence #_y  \n",
      "0     O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
      "1                 O O O O O O O O O O O O O O O O O O O  \n",
      "2       O O O O O O O O O O O O O O O O O O O O O O O O  \n",
      "3     O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
      "4                                 O O O O O O O O O O O  \n",
      "...                                                 ...  \n",
      "1051                          O O D O D O T T O O O T T  \n",
      "1052                    O O T T O D D D D O O O O O O O  \n",
      "1053                                T T T T T T O D D D  \n",
      "1054              T T T T T T T T T O O O O O O O O D D  \n",
      "1055                                      T T T O D D D  \n",
      "\n",
      "[1056 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge the two to form one dataset of all test data\n",
    "df_test_data = pd.merge(df_test_sent, df_test_label, on=\"index\")\n",
    "print(df_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76269017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First five training sentences and their labels:\n",
      "\n",
      "All live births > or = 23 weeks at the University of Vermont in 1995 ( n = 2395 ) were retrospectively analyzed for delivery route , indication for cesarean , gestational age , parity , and practice group ( to reflect risk status ) \n",
      " O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O \n",
      "\n",
      "****************************************************************************************************\n",
      "The total cesarean rate was 14.4 % ( 344 of 2395 ) , and the primary rate was 11.4 % ( 244 of 2144 ) \n",
      " O O O O O O O O O O O O O O O O O O O O O O O O O \n",
      "\n",
      "****************************************************************************************************\n",
      "Abnormal presentation was the most common indication ( 25.6 % , 88 of 344 ) \n",
      " O O O O O O O O O O O O O O O \n",
      "\n",
      "****************************************************************************************************\n",
      "The `` corrected '' cesarean rate ( maternal-fetal medicine and transported patients excluded ) was 12.4 % ( 273 of 2194 ) , and the `` corrected '' primary rate was 9.6 % ( 190 of 1975 ) \n",
      " O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O \n",
      "\n",
      "****************************************************************************************************\n",
      "Arrest of dilation was the most common indication in both `` corrected '' subgroups ( 23.4 and 24.6 % , respectively ) \n",
      " O O O O O O O O O O O O O O O O O O O O O O \n",
      "\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "print(\"First five training sentences and their labels:\\n\")\n",
    "for i in range(5):\n",
    "    print(train_sent[i],\"\\n\",train_label[i],\"\\n\")\n",
    "    print(\"*\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0f9cb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First five training sentences and their labels:\n",
      "\n",
      "Furthermore , when all deliveries were analyzed , regardless of risk status but limited to gestational age > or = 36 weeks , the rates did not change ( 12.6 % , 280 of 2214 ; primary 9.2 % , 183 of 1994 ) \n",
      " O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O \n",
      "\n",
      "****************************************************************************************************\n",
      "As the ambient temperature increases , there is an increase in insensible fluid loss and the potential for dehydration \n",
      " O O O O O O O O O O O O O O O O O O O \n",
      "\n",
      "****************************************************************************************************\n",
      "The daily high temperature ranged from 71 to 104 degrees F and AFI values ranged from 1.7 to 24.7 cm during the study period \n",
      " O O O O O O O O O O O O O O O O O O O O O O O O \n",
      "\n",
      "****************************************************************************************************\n",
      "There was a significant correlation between the 2- , 3- , and 4-day mean temperature and AFI , with the 4-day mean being the most significant ( r = 0.31 , p & # 60 ; 0.001 ) \n",
      " O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O \n",
      "\n",
      "****************************************************************************************************\n",
      "Fluctuations in ambient temperature are inversely correlated to changes in AFI \n",
      " O O O O O O O O O O O \n",
      "\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "print(\"First five training sentences and their labels:\\n\")\n",
    "for i in range(5):\n",
    "    print(test_sent[i],\"\\n\",test_label[i],\"\\n\")\n",
    "    print(\"*\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a112f2",
   "metadata": {},
   "source": [
    "### Count the number of sentences in the processed train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79645548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. sentences in processed train dataset is:  2599\n",
      "No. sentences in processed test dataset is:  1056\n"
     ]
    }
   ],
   "source": [
    "print(\"No. sentences in processed train dataset is: \", len(train_sent))\n",
    "print(\"No. sentences in processed test dataset is: \", len(test_sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee93d851",
   "metadata": {},
   "source": [
    "### Count the number of lines of labels in the processed train and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44646ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. sentences in processed train dataset is:  2599\n",
      "No. sentences in processed test dataset is:  1056\n"
     ]
    }
   ],
   "source": [
    "print(\"No. sentences in processed train dataset is: \", len(train_label))\n",
    "print(\"No. sentences in processed test dataset is: \", len(test_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762beb2f",
   "metadata": {},
   "source": [
    "Concept Identification- We will first explore what are the various concepts present in the dataset. For this, we will use PoS Tagging.\n",
    "\n",
    "We will identify all the words from the corpus that have a tag of NOUN or PROPN (nouns) and prepare a dictionary of their counts. We will then output the top 25 most frequently discussed concepts in the entire corpus.\n",
    "\n",
    "The key thing to check is that we are using both test and train sentences. Note that this is okay because we are using a pre-trained model and applying directly on our data. This is an exploratory analysis on the complete data. Since we are not training anything, there is no point is discarding information in test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015820bf",
   "metadata": {},
   "source": [
    "### Extract those tokens which have NOUN or PROPN as their PoS tag and find their frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78cd2a0",
   "metadata": {},
   "source": [
    "# Creating a combined dataset from training and test sentences, since this is an Exploratory analysis.\n",
    "combined = train_sent + test_sent\n",
    "print(\"Number of sentences in combined dataset (training + test): {}\".format(len(combined)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0004ed18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences in combined dataset (training + test): 3655\n",
      "No. of tokens in combined dataset with PoS tag of 'NOUN' or 'PROPN': 24376\n"
     ]
    }
   ],
   "source": [
    "# Creating a list of tokens which have PoS tag of 'NOUN' or 'PROPN'\n",
    "noun_propn = []         # Initiating list for nouns and proper nouns\n",
    "pos_tag = []            # initiating list for corresponding PoS tags.\n",
    "combined = train_sent + test_sent\n",
    "print(\"Number of sentences in combined dataset (training + test): {}\".format(len(combined)))\n",
    "for sent in combined:\n",
    "    for token in model(sent):\n",
    "        if token.pos_ in ['NOUN', 'PROPN']:\n",
    "           noun_propn.append(token.text)\n",
    "           pos_tag.append(token.pos_)\n",
    "print(\"No. of tokens in combined dataset with PoS tag of 'NOUN' or 'PROPN': {}\".format(len(noun_propn)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93bcb76",
   "metadata": {},
   "source": [
    "### Print the top 25 most common tokens with NOUN or PROPN PoS tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81039bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 25 comon tokens with PoS tag of 'NOUN' or 'PROPN' \n",
      "\n",
      "NOUN_PROPN\n",
      "patients        492\n",
      "treatment       281\n",
      "%               247\n",
      "cancer          200\n",
      "therapy         175\n",
      "study           154\n",
      "disease         142\n",
      "cell            140\n",
      "lung            116\n",
      "group            94\n",
      "chemotherapy     88\n",
      "gene             87\n",
      "effects          85\n",
      "results          79\n",
      "women            77\n",
      "use              74\n",
      "TO_SEE           74\n",
      "surgery          71\n",
      "cases            71\n",
      "risk             71\n",
      "analysis         70\n",
      "rate             67\n",
      "response         66\n",
      "survival         65\n",
      "children         64\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "noun_pos = pd.DataFrame({\"NOUN_PROPN\":noun_propn,\"POS_tag\":pos_tag})\n",
    "print(\"Top 25 comon tokens with PoS tag of 'NOUN' or 'PROPN' \\n\")\n",
    "print(noun_pos[\"NOUN_PROPN\"].value_counts().head(25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9c3892",
   "metadata": {},
   "source": [
    "# Defining features for CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4178f183",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Let's define the features to get the feature value for one word.\n",
    "\n",
    "def getFeaturesForOneWord(sentence, pos, pos_tags):\n",
    "  word = sentence[pos]\n",
    "\n",
    "  features = [\n",
    "    'word.lower=' + word.lower(), # serves as word id\n",
    "    'word[-3:]=' + word[-3:],     # last three characters\n",
    "    'word[-2:]=' + word[-2:],     # last two characters\n",
    "    'word.isupper=%s' % word.isupper(),  # is the word in all uppercase\n",
    "    'word.isdigit=%s' % word.isdigit(),  # is the word a number\n",
    "    'word.startsWithCapital=%s' % word[0].isupper(), # is the word starting with a capital letter\n",
    "    'word.pos=' + pos_tags[pos]\n",
    "  ]\n",
    "\n",
    "  #Use the previous word also while defining features\n",
    "  if(pos > 0):\n",
    "    prev_word = sentence[pos-1]\n",
    "    features.extend([\n",
    "    'prev_word.lower=' + prev_word.lower(),\n",
    "    'prev_word.isupper=%s' % prev_word.isupper(),\n",
    "    'prev_word.isdigit=%s' % prev_word.isdigit(),\n",
    "    'prev_word.startsWithCapital=%s' % prev_word[0].isupper(),\n",
    "    'prev_word.pos=' + pos_tags[pos-1]\n",
    "  ])\n",
    "  # Mark the begining and the end words of a sentence correctly in the form of features.\n",
    "  else:\n",
    "    features.append('BEG') # feature to track begin of sentence\n",
    "\n",
    "  if(pos == len(sentence)-1):\n",
    "    features.append('END') # feature to track end of sentence\n",
    "\n",
    "  return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153ccdae",
   "metadata": {},
   "source": [
    "## Getting the features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d17ad2",
   "metadata": {},
   "source": [
    "### Write a code/function to get the features for a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88b0f432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get features for a sentence.\n",
    "def getFeaturesForOneSentence(sentence):\n",
    "\n",
    "    # We need to get the pos_tags to be passed to the function\n",
    "    processed_sent = model(sentence)\n",
    "    postags = []\n",
    "\n",
    "    for each_token in processed_sent:\n",
    "        postags.append(each_token.pos_)\n",
    "\n",
    "    sentence_list = sentence.split()\n",
    "    return [getFeaturesForOneWord(sentence_list, pos, postags) for pos in range(len(sentence_list))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141184f3",
   "metadata": {},
   "source": [
    "### Write a code/function to get the labels of a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab32cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the labels for a sentence.\n",
    "def getLabelsInListForOneSentence(labels):\n",
    "  return labels.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e11f28",
   "metadata": {},
   "source": [
    "# Define input and target variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063c7612",
   "metadata": {},
   "source": [
    "### Define the features values for each sentence as input variable for CRF model in test and the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08fcf6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [getFeaturesForOneSentence(sentence) for sentence in train_sent]\n",
    "X_test = [getFeaturesForOneSentence(sentence) for sentence in test_sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9388592",
   "metadata": {},
   "source": [
    "### Define the labels as the target variable for test and the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57cc6aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = [getLabelsInListForOneSentence(labels) for labels in train_label]\n",
    "Y_test = [getLabelsInListForOneSentence(labels) for labels in test_label]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c008b8",
   "metadata": {},
   "source": [
    "# Build the CRF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ffd627be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the file specified.\n"
     ]
    }
   ],
   "source": [
    "pip install -U 'scikit-learn<0.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2c398bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the CRF model.\n",
    "crf = sklearn_crfsuite.CRF(max_iterations=100)\n",
    "try:\n",
    "    crf.fit(X_train, Y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "predictions = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff8ac83",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cdfa38",
   "metadata": {},
   "source": [
    "### Predict the labels of each of the tokens in each sentence of the test dataset that has been pre processed earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf07388a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d54896",
   "metadata": {},
   "source": [
    "### Calculate the f1 score using the actual labels and the predicted labels of the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5dc91b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score is: 0.9053\n"
     ]
    }
   ],
   "source": [
    "f1_score = metrics.flat_f1_score(Y_test, Y_pred, average='weighted')\n",
    "print(f\"F1 score is: {round(f1_score,4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e879b0c8",
   "metadata": {},
   "source": [
    "An f1-score of nearly 91% is fairly decent.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21459d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: CONCLUSIONS : A complete genomic screen in families affected with late-onset AD identified 4 regions of interest after follow-up\n",
      "Orig Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "# Print the orginal labels and predicted labels for the sentence  in test data, which is at index value 25.\n",
    "id = 25\n",
    "print(\"Sentence:\",test_sent[id])\n",
    "print(\"Orig Labels:\", Y_test[id])\n",
    "print(\"Pred Labels:\", Y_pred[id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b1208d",
   "metadata": {},
   "source": [
    "# Identifying Diseases and Treatments using Custom NER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01341e4",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We now use the CRF model's prediction to prepare a record of diseases identified in the corpus and treatments used for the diseases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c639883",
   "metadata": {},
   "source": [
    "Create the logic to get all the predicted treatments (T) labels corresponding to each disease (D) label in the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e95c9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Disease</th>\n",
       "      <th>Treatments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Disease, Treatments]\n",
       "Index: []"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_n_T_DF = pd.DataFrame([], columns=[\"Disease\", \"Treatments\"])\n",
    "D_n_T_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03a6b1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Y_pred)):\n",
    "\n",
    "  p_val = Y_pred[i]\n",
    "  dise = \"\"\n",
    "  treat = \"\"\n",
    "\n",
    "  DTO = set(p_val)\n",
    "  if \"D\" in DTO and \"T\" in DTO:\n",
    "\n",
    "    for j in range(len(p_val)):\n",
    "      if p_val[j] == 'D':\n",
    "        dise += test_sent[i].split()[j] + \" \"\n",
    "      elif p_val[j] == 'T':\n",
    "        treat += test_sent[i].split()[j] + \" \"\n",
    "\n",
    "    dise = dise.strip()\n",
    "    treat = treat.strip()\n",
    "\n",
    "    present = D_n_T_DF.loc[(D_n_T_DF.Disease == dise), [\"Disease\"]]\n",
    "    if present.size:\n",
    "      treatment_df = D_n_T_DF.loc[(D_n_T_DF.Disease == dise), [\"Treatments\"]]\n",
    "      treatment = treatment_df.values.tolist()\n",
    "      treatment.extend([treat])\n",
    "      D_n_T_DF.loc[(D_n_T_DF.Disease == dise), [\"Treatments\"]] = [[treatment]]\n",
    "\n",
    "    else:\n",
    "      D_n_T_DF = pd.concat([D_n_T_DF, pd.DataFrame([[dise, treat]], columns=D_n_T_DF.columns )])   \n",
    "    D_n_T_DF = D_n_T_DF.set_index(np.arange(D_n_T_DF.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb67d9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Disease</th>\n",
       "      <th>Treatments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hereditary retinoblastoma</td>\n",
       "      <td>radiotherapy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>myocardial infarction</td>\n",
       "      <td>warfarin with 80 mg aspirin , or 1 mg warfarin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unstable angina</td>\n",
       "      <td>roxithromycin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>coronary-artery disease</td>\n",
       "      <td>Antichlamydial antibiotics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>primary pulmonary hypertension ( PPH )</td>\n",
       "      <td>fenfluramines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>temporomandibular joint arthropathy</td>\n",
       "      <td>arthroscopic treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>severe secondary peritonitis</td>\n",
       "      <td>Surgical management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>hepatic metastases from colorectal cancer</td>\n",
       "      <td>Hepatic arterial infusion of chemotherapy afte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>chronic renal failure</td>\n",
       "      <td>Epoetin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>epithelial ovarian cancer</td>\n",
       "      <td>High-dose chemotherapy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Disease  \\\n",
       "0                    hereditary retinoblastoma   \n",
       "1                        myocardial infarction   \n",
       "2                              unstable angina   \n",
       "3                      coronary-artery disease   \n",
       "4       primary pulmonary hypertension ( PPH )   \n",
       "..                                         ...   \n",
       "96         temporomandibular joint arthropathy   \n",
       "97                severe secondary peritonitis   \n",
       "98   hepatic metastases from colorectal cancer   \n",
       "99                       chronic renal failure   \n",
       "100                  epithelial ovarian cancer   \n",
       "\n",
       "                                            Treatments  \n",
       "0                                         radiotherapy  \n",
       "1    warfarin with 80 mg aspirin , or 1 mg warfarin...  \n",
       "2                                        roxithromycin  \n",
       "3                           Antichlamydial antibiotics  \n",
       "4                                        fenfluramines  \n",
       "..                                                 ...  \n",
       "96                              arthroscopic treatment  \n",
       "97                                 Surgical management  \n",
       "98   Hepatic arterial infusion of chemotherapy afte...  \n",
       "99                                             Epoetin  \n",
       "100                             High-dose chemotherapy  \n",
       "\n",
       "[101 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_n_T_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dcf170",
   "metadata": {},
   "source": [
    "### Predict the treatment for the disease name: 'hereditary retinoblastoma'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f15e11a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Disease</th>\n",
       "      <th>Treatments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hereditary retinoblastoma</td>\n",
       "      <td>radiotherapy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Disease    Treatments\n",
       "0  hereditary retinoblastoma  radiotherapy"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dise = 'hereditary retinoblastoma'\n",
    "D_n_T_DF.loc[(D_n_T_DF.Disease == dise), [\"Disease\", \"Treatments\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bdd2b0",
   "metadata": {},
   "source": [
    "Here we can see the the treatment for the disease name 'hereditary retinoblastoma' is radiotherapy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34792c0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
